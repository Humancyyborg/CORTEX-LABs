{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ7IAbZ5QQwvvE5VPHRUOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeiChenc/Aurevia/blob/main/EEGpreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZX-LAjef8mf",
        "outputId": "a5217733-5ae8-42f5-e0d4-7db896860607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install mne h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlEJr8urgENj",
        "outputId": "49cb5b6e-e6ba-4352-c846-d1c8f343951d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile preprocess.py\n",
        "#one-by-one pipeline for chb05~chb23\n",
        "import os, re, glob, shutil, gc, numpy as np, mne, h5py, subprocess\n",
        "\n",
        "#initial settings\n",
        "FS_TARGET = 256.0\n",
        "BANDPASS = (0.5, 45.0)\n",
        "NOTCH_HZ = 60.0\n",
        "WIN_SEC = 2.0\n",
        "STRIDE_SEC = 0.5\n",
        "PRE_ICTAL_MIN = 30\n",
        "N_CHANNELS_KEEP = 4\n",
        "\n",
        "\n",
        "BASE_URL = \"https://physionet.org/files/chbmit/1.0.0\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/chbmit\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/processed_data_npy\"\n",
        "CACHE_DIR = \"/content/drive/MyDrive/processed_cache\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def run(cmd):\n",
        "    \"\"\"執行 shell 指令並即時輸出（遇錯不中斷流程）\"\"\"\n",
        "    print(f\"[CMD] {cmd}\")\n",
        "    try:\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[WARN] command failed: {e}\")\n",
        "\n",
        "def free_gb(path=\"/content/drive/MyDrive\"):\n",
        "    st = os.statvfs(path)\n",
        "    return st.f_bavail * st.f_frsize / (1024**3)\n",
        "\n",
        "def human(n):\n",
        "    return f\"{n:.2f} GB\"\n",
        "\n",
        "def download_patient(patient: str):\n",
        "    pdir = os.path.join(DATA_DIR, patient)\n",
        "    os.makedirs(pdir, exist_ok=True)\n",
        "\n",
        "    cmd = (\n",
        "        f'cd \"{DATA_DIR}\" && '\n",
        "        f'wget -r -np -nH --cut-dirs=3 -N '\n",
        "        f'-A \"*.edf,*.txt\" \"{BASE_URL}/{patient}/\"'\n",
        "    )\n",
        "    run(cmd)\n",
        "    # edf files\n",
        "    edfs = glob.glob(os.path.join(pdir, f\"{patient}_*.edf\"))\n",
        "    if not edfs:\n",
        "        raise RuntimeError(f\"[ERR] {patient}: no EDF downloaded.\")\n",
        "    print(f\"[INFO] {patient}: EDF count = {len(edfs)}\")\n",
        "\n",
        "# read summary\n",
        "def parse_summary_any(summary_path: str):\n",
        "    if not os.path.exists(summary_path):\n",
        "        print(f\"[WARN] summary not found: {summary_path} -> treat as no-seizure\")\n",
        "        return {}\n",
        "    with open(summary_path, \"r\", errors=\"ignore\") as f:\n",
        "        txt = f.read()\n",
        "    blocks = re.split(r\"(?i)\\bFile Name:\\s*\", txt)\n",
        "    seizures = {}\n",
        "    for b in blocks[1:]:\n",
        "        fname = b.splitlines()[0].strip()\n",
        "        start_pat = r\"(?i)Seizure(?:\\s+\\d+)?\\s+Start\\s+Time:\\s*(\\d+)\\s*(?:sec|seconds)?\"\n",
        "        end_pat   = r\"(?i)Seizure(?:\\s+\\d+)?\\s+End\\s+Time:\\s*(\\d+)\\s*(?:sec|seconds)?\"\n",
        "        starts = [int(x) for x in re.findall(start_pat, b)]\n",
        "        ends   = [int(x) for x in re.findall(end_pat, b)]\n",
        "        pairs = [(s, e) for s, e in zip(starts, ends) if e >= s]\n",
        "        seizures[fname] = pairs\n",
        "    return seizures\n",
        "\n",
        "# read edfs\n",
        "def load_raw_mne(edf_path: str):\n",
        "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
        "    if N_CHANNELS_KEEP and len(raw.ch_names) > N_CHANNELS_KEEP:\n",
        "        raw.pick_channels(raw.ch_names[:N_CHANNELS_KEEP])\n",
        "    raw.filter(BANDPASS[0], BANDPASS[1], fir_design=\"firwin\", verbose=False)\n",
        "    if NOTCH_HZ:\n",
        "        try:\n",
        "            raw.notch_filter(freqs=[NOTCH_HZ], verbose=False)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] notch_filter failed on {edf_path}: {e}\")\n",
        "    if raw.info[\"sfreq\"] != FS_TARGET:\n",
        "        raw.resample(FS_TARGET, npad=\"auto\", verbose=False)\n",
        "    return raw\n",
        "\n",
        "def make_windows_and_labels(raw: mne.io.Raw, ictal_spans_sec, pre_minutes: int):\n",
        "    x = raw.get_data()  # (C, T)\n",
        "    fs = float(raw.info[\"sfreq\"]); T = x.shape[1]\n",
        "    win = int(round(WIN_SEC * fs)); hop = int(round(STRIDE_SEC * fs))\n",
        "    if T < win:\n",
        "        return np.empty((0,0,0), dtype=np.float32), np.empty((0,), dtype=np.int64)\n",
        "\n",
        "    #backtesting pre-spans in their files\n",
        "    pre_spans = []\n",
        "    for s, e in ictal_spans_sec:\n",
        "        a = max(0.0, float(s) - pre_minutes*60.0)\n",
        "        b = float(s)\n",
        "        if b > a: pre_spans.append((a, b))\n",
        "\n",
        "    def overlap(t0, t1, spans):\n",
        "        for a, b in spans:\n",
        "            if not (t1 <= a or t0 >= b):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    starts = np.arange(0, T - win + 1, hop, dtype=np.int64)\n",
        "    X_list, y_list = [], []\n",
        "    for st in starts:\n",
        "        ed = st + win\n",
        "        seg = x[:, st:ed]\n",
        "        seg = (seg - seg.mean(axis=1, keepdims=True)) / (seg.std(axis=1, keepdims=True) + 1e-6)\n",
        "        seg = seg.T.astype(np.float32)  # (win, C)\n",
        "        t0, t1 = st/fs, ed/fs\n",
        "        y = 0\n",
        "        if ictal_spans_sec and overlap(t0, t1, ictal_spans_sec):\n",
        "            y = 2\n",
        "        elif pre_spans and overlap(t0, t1, pre_spans):\n",
        "            y = 1\n",
        "        X_list.append(seg); y_list.append(y)\n",
        "\n",
        "    if not X_list:\n",
        "        return np.empty((0,0,0), dtype=np.float32), np.empty((0,), dtype=np.int64)\n",
        "    return np.stack(X_list, axis=0), np.asarray(y_list, dtype=np.int64)\n",
        "\n",
        "def windows_for(edf_path, spans):\n",
        "    try:\n",
        "        raw = load_raw_mne(edf_path)\n",
        "        return make_windows_and_labels(raw, spans, PRE_ICTAL_MIN)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] {edf_path}: {e}\")\n",
        "        return np.empty((0,0,0), dtype=np.float32), np.empty((0,), dtype=np.int64)\n",
        "\n",
        "# HDF5\n",
        "def h5_init(h5_path, win, C):\n",
        "    if not os.path.exists(h5_path):\n",
        "        with h5py.File(h5_path, \"w\") as f:\n",
        "            f.create_dataset(\"X\", shape=(0, win, C), maxshape=(None, win, C),\n",
        "                             dtype=\"float32\", chunks=(2048, win, C), compression=\"lzf\")\n",
        "            f.create_dataset(\"y\", shape=(0,), maxshape=(None,),\n",
        "                             dtype=\"int64\",   chunks=(8192,), compression=\"lzf\")\n",
        "\n",
        "def h5_append(h5_path, Xb, yb):\n",
        "    with h5py.File(h5_path, \"a\") as f:\n",
        "        n0 = f[\"X\"].shape[0]; n1 = n0 + Xb.shape[0]\n",
        "        f[\"X\"].resize((n1, Xb.shape[1], Xb.shape[2])); f[\"X\"][n0:n1] = Xb\n",
        "        f[\"y\"].resize((n1,)); f[\"y\"][n0:n1] = yb\n",
        "        f.flush()\n",
        "\n",
        "def h5_to_npy(h5_path, out_x, out_y, batch=20000):\n",
        "    with h5py.File(h5_path, \"r\") as f:\n",
        "        N, win, C = f[\"X\"].shape\n",
        "        X_mm = np.lib.format.open_memmap(out_x, mode=\"w+\", dtype=\"float32\", shape=(N, win, C))\n",
        "        Y_mm = np.lib.format.open_memmap(out_y, mode=\"w+\", dtype=\"int64\",   shape=(N,))\n",
        "        i = 0\n",
        "        while i < N:\n",
        "            j = min(i + batch, N)\n",
        "            X_mm[i:j] = f[\"X\"][i:j]\n",
        "            Y_mm[i:j] = f[\"y\"][i:j]\n",
        "            i = j\n",
        "        del X_mm, Y_mm\n",
        "    return N\n",
        "\n",
        "# filiiing npy for each patient\n",
        "def process_patient(patient: str):\n",
        "    print(\"=\"*90)\n",
        "    print(f\"[START] {patient} | free={human(free_gb())}\")\n",
        "\n",
        "    pdir = os.path.join(DATA_DIR, patient)\n",
        "    h5_path = os.path.join(CACHE_DIR, f\"{patient}.h5\")\n",
        "    out_x = os.path.join(OUTPUT_DIR, f\"X_{patient}.npy\")\n",
        "    out_y = os.path.join(OUTPUT_DIR, f\"y_{patient}.npy\")\n",
        "\n",
        "    #skip the existing\n",
        "    if os.path.exists(out_x) and os.path.exists(out_y):\n",
        "        print(f\"[SKIP] {patient} npy already exists.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.isdir(pdir) or not glob.glob(os.path.join(pdir, f\"{patient}_*.edf\")):\n",
        "        print(f\"[DL] downloading {patient} …\")\n",
        "        download_patient(patient)\n",
        "\n",
        "    # summary\n",
        "    summary_path = os.path.join(pdir, f\"{patient}-summary.txt\")\n",
        "    seizures_by_file = parse_summary_any(summary_path)\n",
        "\n",
        "    #  append to H5\n",
        "    edf_files = sorted(glob.glob(os.path.join(pdir, f\"{patient}_*.edf\")))\n",
        "    h5_ready = False\n",
        "    total_files = 0\n",
        "\n",
        "    for edf_path in edf_files:\n",
        "        fname = os.path.basename(edf_path)\n",
        "        spans = seizures_by_file.get(fname, [])\n",
        "        Xb, yb = windows_for(edf_path, spans)\n",
        "        if Xb.size == 0:\n",
        "            print(f\"[INFO] {fname}: windows=0 (skip)\")\n",
        "            continue\n",
        "        if not h5_ready:\n",
        "            win, C = Xb.shape[1], Xb.shape[2]\n",
        "            h5_init(h5_path, win, C)\n",
        "            h5_ready = True\n",
        "        h5_append(h5_path, Xb, yb)\n",
        "        cnt = dict(zip(*np.unique(yb, return_counts=True)))\n",
        "        print(f\"[OK] {fname}: windows={Xb.shape[0]}, labels={cnt}\")\n",
        "        del Xb, yb, cnt; gc.collect()\n",
        "        total_files += 1\n",
        "\n",
        "    if not h5_ready:\n",
        "        raise RuntimeError(f\"[ERR] {patient}: no data appended to H5.\")\n",
        "\n",
        "    # convert to npy\n",
        "    N = h5_to_npy(h5_path, out_x, out_y, batch=20000)\n",
        "    y = np.load(out_y, mmap_mode=\"r\")\n",
        "    from collections import Counter\n",
        "    print(f\"[SAVE] {patient}: X.shape={[N, win, C]}, y.shape={(N,)}, labels={Counter(np.asarray(y))}\")\n",
        "\n",
        "    # delete original files and keep npy\n",
        "    print(f\"[CLEAN] deleting raw EDF and cache for {patient} …\")\n",
        "    try:\n",
        "        shutil.rmtree(pdir)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] remove {pdir} failed: {e}\")\n",
        "    try:\n",
        "        os.remove(h5_path)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] remove {h5_path} failed: {e}\")\n",
        "\n",
        "    print(f\"[DONE] {patient} | free={human(free_gb())}\")\n",
        "\n",
        "# for all patient\n",
        "patients = [f\"chb{n:02d}\" for n in range(5, 24)]\n",
        "\n",
        "for patient in patients:\n",
        "    # Aware the storage\n",
        "    if free_gb() < 9.0:\n",
        "        print(f\"[WAIT] free space={human(free_gb())} too low; please free space and rerun this cell.\")\n",
        "        break\n",
        "    process_patient(patient)\n"
      ],
      "metadata": {
        "id": "ejCEE6z0gETQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8352b4a1-ed2b-4b56-a13f-b16a6ba31b64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/processed_data_npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YxZWyd2Tcq5",
        "outputId": "e2342dae-af65-44e2-9edd-b85bb2b5a32d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_chb05.npy  X_chb07.npy  y_chb04.npy  y_chb06.npy  y_chb08.npy\n",
            "X_chb06.npy  X_chb08.npy  y_chb05.npy  y_chb07.npy  y_chb09.npy\n"
          ]
        }
      ]
    }
  ]
}