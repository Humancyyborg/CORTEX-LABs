{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1kX504izmG2Y0bXXmJi-1eQa2qTYFuZ1g",
      "authorship_tag": "ABX9TyOjWbNvvk1fY9X0WTLaRujI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeiChenc/Aurevia/blob/main/Aurevia_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shell: # Install deps\n",
        "pip install numpy scipy mne pandas scikit-learn matplotlib\n",
        "pip install tensorflow torch torchaudio torchvision\n",
        "pip install tensorflow-model_optimization  # for quantization\n",
        "pip install wfdb  # CHB-MIT dataset access\n",
        "pip install h5py mlflow\n",
        "pip install mne"
      ],
      "metadata": {
        "id": "wWY8CkyIOtMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx9Le6yAFgkq",
        "outputId": "7a741945-426e-4ac2-d167-0b0a282e450a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking chb0*.npy\n",
        "import numpy as np, collections, os, pathlib\n",
        "p = \"/content/drive/MyDrive/processed_data_npy\"\n",
        "X = np.load(os.path.join(p, \"X_chb05.npy\"))\n",
        "y = np.load(os.path.join(p, \"y_chb05.npy\"))\n",
        "print(X.shape, y.shape)\n",
        "print(collections.Counter(y))\n",
        "\n"
      ],
      "metadata": {
        "id": "Kv92kN25soe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd81b928-f0d3-40ae-cd8b-8cc77ef37b0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(273506, 512, 4) (273506,)\n",
            "Counter({np.int64(0): 258575, np.int64(1): 13800, np.int64(2): 1131})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model training algo"
      ],
      "metadata": {
        "id": "l-wihOdG7ehy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from collections import Counter\n",
        "import os"
      ],
      "metadata": {
        "id": "buLVAlguw2Gc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data path\n",
        "BASE_PATH = \"/content/\"\n",
        "PATIENTS = [\"chb05\", \"chb06\", \"chb07\", \"chb08\"]\n",
        "\n",
        "\n",
        "X_data_list = []\n",
        "y_data_list = []\n",
        "\n",
        "print(f\"from {BASE_PATH} download files...\")\n",
        "\n",
        "for patient_id in PATIENTS:\n",
        "    x_file_path = os.path.join(BASE_PATH, f\"X_{patient_id}.npz\")\n",
        "    y_file_path = os.path.join(BASE_PATH, f\"y_{patient_id}.npz\")\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(x_file_path) or not os.path.exists(y_file_path):\n",
        "            print(f\"lost files {patient_id}\")\n",
        "            print(f\"   lost: {x_file_path} or {y_file_path}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        X_loaded = np.load(x_file_path, allow_pickle=True)['arr_0']\n",
        "        X_data_list.append(X_loaded)\n",
        "\n",
        "        y_loaded = np.load(y_file_path, allow_pickle=True)['arr_0']\n",
        "        y_data_list.append(y_loaded)\n",
        "\n",
        "        print(f\"loaded patient {patient_id} file successfully。X shape: {X_loaded.shape}, y shape: {y_loaded.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"error：load patient {patient_id} file, {e}\")\n",
        "        continue\n",
        "\n",
        "# Merge the files to one\n",
        "\n",
        "if X_data_list:\n",
        "    X_combined = np.concatenate(X_data_list, axis=0)\n",
        "    y_combined = np.concatenate(y_data_list, axis=0)\n",
        "\n",
        "    print(\"\\n--- 載入完成 ---\")\n",
        "    print(f\"All patients' file  x shape : {X_combined.shape}\")\n",
        "    print(f\"All patients' file y shape: {y_combined.shape}\")\n",
        "else:\n",
        "    print(\"\\n--- Fall to load ---\")\n",
        "\n",
        "#X_combined & y_combined created\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZToOwv78wZx9",
        "outputId": "45611e5d-28a2-49aa-e87c-1988541aeb37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from /content/ download files...\n",
            "lost files chb05\n",
            "   lost: /content/X_chb05.npz or /content/y_chb05.npz\n",
            "lost files chb06\n",
            "   lost: /content/X_chb06.npz or /content/y_chb06.npz\n",
            "lost files chb07\n",
            "   lost: /content/X_chb07.npz or /content/y_chb07.npz\n",
            "lost files chb08\n",
            "   lost: /content/X_chb08.npz or /content/y_chb08.npz\n",
            "\n",
            "--- Fall to load ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile heavy_model_2.py\n",
        "import os, json, numpy as np\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# ========= Configuration (aligned with your preprocessing) =========\n",
        "DATA_DIR   = \"/content/drive/MyDrive/processed_data_npy\"   # .npy only\n",
        "PATIENTS   = [\"chb05\",\"chb06\",\"chb07\",\"chb08\"]             # LOPOCV set\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/models\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "SAMPLING_RATE_HZ    = 256.0\n",
        "WINDOW_DURATION_SEC = 2.0\n",
        "OVERLAP_PERCENT     = 0.75\n",
        "STRIDE_SEC          = WINDOW_DURATION_SEC * (1.0 - OVERLAP_PERCENT)  # 0.5s\n",
        "\n",
        "# --- Global parameters for thresholding and smoothing ---\n",
        "THRESH_SCAN_STEP = 0.05   # Step size for threshold search\n",
        "FPH_CAP          = 0.10   # Max False Positives Per Hour constraint\n",
        "MIN_RUN_LEN      = 2      # Minimum consecutive positive windows for smoothing/event\n",
        "\n",
        "# ========= I/O (npy only) =========\n",
        "def load_patient_npy(data_dir, pid):\n",
        "    x_path = os.path.join(data_dir, f\"X_{pid}.npy\")\n",
        "    y_path = os.path.join(data_dir, f\"y_{pid}.npy\")\n",
        "    if not (os.path.exists(x_path) and os.path.exists(y_path)):\n",
        "        raise FileNotFoundError(f\"Missing {x_path} or {y_path}\")\n",
        "    X = np.load(x_path, mmap_mode=\"r\")\n",
        "    y = np.load(y_path, mmap_mode=\"r\")\n",
        "    return np.asarray(X), np.asarray(y)  # ensure ndarray for TF/Keras\n",
        "\n",
        "\n",
        "# ========= Metrics: FP/h and Warning Time =========\n",
        "def fp_per_hour_events(y_true, y_pred, stride_sec= STRIDE_SEC, refractory_min=10, min_run_len=2):\n",
        "\n",
        "    y_true= np.asarray(y_true)\n",
        "    # FIX: Typo 'np.asarry' -> 'np.asarray' and ensure conversion\n",
        "    y_pred = np.asarray(y_pred)\n",
        "\n",
        "    # FIX: Typo 'y_ture' -> 'y_true'\n",
        "    inter_mask = (y_true == 0)\n",
        "    inter_idx = np.where(inter_mask)[0]\n",
        "    if inter_idx.size == 0:\n",
        "        return np.inf\n",
        "\n",
        "    y_pred_inter = (y_pred[inter_mask] > 0).astype(int)\n",
        "    # FIX: IndentationError corrected here and in the block below\n",
        "    n = len(y_pred_inter)\n",
        "\n",
        "    fp_events = 0\n",
        "    i = 0\n",
        "    refr_windows = int((refractory_min * 60.0) / max(stride_sec, 1e-9))\n",
        "    while i < n:\n",
        "        if y_pred_inter[i] == 1:\n",
        "            # find positive run\n",
        "            j = i\n",
        "            while j < n and y_pred_inter[j] == 1:\n",
        "                j += 1\n",
        "            run_len = j - i\n",
        "            if run_len >= min_run_len:\n",
        "                fp_events += 1\n",
        "                i = min(j + refr_windows, n)  # skip refractory\n",
        "            else:\n",
        "                i = j\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    hours = (inter_idx.size * stride_sec) / 3600.0\n",
        "    return fp_events / max(hours, 1e-9)\n",
        "\n",
        "# ========= Smoothing: minimal consecutive positives =========\n",
        "# ** change k window majority smoothing to minimal run smoothing\n",
        "def min_consecutive_positive(y_pred_win: np.ndarray, min_len: int = 2) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Keep positive runs only if they reach a minimum consecutive length (min_len).\n",
        "    y_pred_win: 0=inter-ictal, 1=pre-ictal, 2=ictal\n",
        "    \"\"\"\n",
        "    y = np.asarray(y_pred_win).copy()\n",
        "    n = len(y)\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        if y[i] > 0:\n",
        "            j = i\n",
        "            while j < n and y[j] > 0:\n",
        "                j += 1\n",
        "            if (j - i) < min_len:\n",
        "                y[i:j] = 0\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return y\n",
        "\n",
        "def compute_warning_time_minutes(y_true, y_hat_bin, stride_sec=STRIDE_SEC):\n",
        "    \"\"\"\n",
        "    For each ictal episode onset (first window of label==2 after not-2), look backward to the\n",
        "    first window flagged positive by the model and compute time difference in minutes.\n",
        "    \"\"\"\n",
        "    y = np.asarray(y_true)\n",
        "    onsets = []\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 2 and (i == 0 or y[i-1] != 2):\n",
        "            onsets.append(i)\n",
        "    if not onsets:\n",
        "        return (0.0, 0.0, 0, 0)\n",
        "    detected = []\n",
        "    for t0 in onsets:\n",
        "        j = t0\n",
        "        while j >= 0 and y_hat_bin[j] == 0:\n",
        "            j -= 1\n",
        "        if j >= 0:\n",
        "            minutes = (t0 - j) * stride_sec / 60.0\n",
        "            detected.append(minutes)\n",
        "    if not detected:\n",
        "        return (0.0, 0.0, len(onsets), 0)\n",
        "    arr = np.asarray(detected)\n",
        "    return (float(arr.mean()), float(np.median(arr)), len(onsets), len(arr))\n",
        "\n",
        "# Threshold selection on validation ** max sensitivity under constrain- FPH <= cap, making sure the sens won't be 0\n",
        "def pick_threshold_on_val(\n",
        "    p_val: np.ndarray,\n",
        "    y_val: np.ndarray,\n",
        "    step: float = 0.01,\n",
        "    fph_cap: float = 0.10,\n",
        "    stride_sec: float = 0.5,\n",
        "    min_sens: float = 0.60,\n",
        "    objective: str = \"sens\",\n",
        "    refractory_min: int = 10,\n",
        "    min_run_len: int = 2,\n",
        "):\n",
        "    \"\"\"\n",
        "    Select a threshold under an FP/hour cap (event-level).\n",
        "    objective: \"sens\" (maximize sensitivity) or \"f1_pos\" (maximize F1 of positive vs non-positive).\n",
        "    If no threshold reaches min_sens within the cap, fall back to the best F1 within the cap; if still none, best overall F1.\n",
        "    \"\"\"\n",
        "    p_pos = p_val[:, 1] + p_val[:, 2]\n",
        "    y_pos = (y_val > 0).astype(int)\n",
        "\n",
        "    records = []\n",
        "    for th in np.arange(0.05, 0.96, step):\n",
        "        y_hat_bin = (p_pos >= th).astype(int)\n",
        "        sens = (np.sum((y_pos == 1) & (y_hat_bin == 1)) / max(np.sum(y_pos == 1), 1))\n",
        "        # === ** use event-level FP/h ===\n",
        "        # Proper call (use original labels and predictions at window-level):\n",
        "        fph  = fp_per_hour_events(y_true=y_val, y_pred=y_hat_bin,  # event-level on inter-ictal\n",
        "                                  stride_sec=stride_sec,\n",
        "                                  refractory_min=refractory_min,\n",
        "                                  min_run_len=min_run_len)\n",
        "        f1   = f1_score(y_pos, y_hat_bin, zero_division=0)\n",
        "        records.append((float(th), float(sens), float(fph), float(f1)))\n",
        "\n",
        "    feasible = [r for r in records if r[2] <= fph_cap]\n",
        "\n",
        "    def pick_best(pool, prefer=\"sens\"):\n",
        "        if prefer == \"sens\":\n",
        "            return max(pool, key=lambda r: (r[1], r[3]))  # sens, then F1\n",
        "        else:\n",
        "            return max(pool, key=lambda r: (r[3], r[1]))  # F1, then sens\n",
        "\n",
        "    if feasible:\n",
        "        good = [r for r in feasible if r[1] >= min_sens]\n",
        "        pool = good if good else feasible\n",
        "        best = pick_best(pool, \"sens\" if objective == \"sens\" else \"f1\")\n",
        "    else:\n",
        "        best = pick_best(records, \"f1\")\n",
        "\n",
        "    th, sens, fph, f1 = best\n",
        "    meta = {\n",
        "        \"rule\": \"sens_or_f1_under_event_fph_cap\",\n",
        "        \"th\": th, \"sens\": sens, \"fph\": fph, \"f1_pos\": f1,\n",
        "        \"params\": {\"refractory_min\": refractory_min, \"min_run_len\": min_run_len}\n",
        "    }\n",
        "    return th, meta\n",
        "\n",
        "\n",
        "# ========= Model =========\n",
        "def build_model(input_shape, export_safe: bool = False):\n",
        "    lstm_common = dict(\n",
        "        activation='tanh',\n",
        "        recurrent_activation='sigmoid',\n",
        "        use_bias=True,\n",
        "        unit_forget_bias=True,\n",
        "    )\n",
        "    if export_safe:\n",
        "        lstm_common.update(dict(recurrent_dropout=0.1, implementation=1))\n",
        "\n",
        "    return Sequential([\n",
        "        Conv1D(64, 5, activation='relu', kernel_initializer=HeNormal(), input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Bidirectional(LSTM(128, return_sequences=True, **lstm_common)),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64, **lstm_common)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(128, activation='relu', kernel_initializer=HeNormal()),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "# ========= One LOPOCV fold =========\n",
        "def run_fold(test_pid, val_pid, train_pids):\n",
        "    print(f\"\\n===== FOLD | test={test_pid} val={val_pid} train={train_pids} =====\")\n",
        "    # Load data\n",
        "    X_tr_list, y_tr_list = [], []\n",
        "    for p in train_pids:\n",
        "        Xp, yp = load_patient_npy(DATA_DIR, p)\n",
        "        X_tr_list.append(Xp); y_tr_list.append(yp)\n",
        "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
        "\n",
        "    X_va, y_va = load_patient_npy(DATA_DIR, val_pid)\n",
        "    X_te, y_te = load_patient_npy(DATA_DIR, test_pid)\n",
        "\n",
        "    # Class weights from the RAW train distribution\n",
        "    class_counts  = Counter(y_tr)\n",
        "    n_class       = len(class_counts)\n",
        "    total_samples = sum(class_counts.values())\n",
        "    class_weights = {cls: total_samples / (n_class * cnt) for cls, cnt in class_counts.items()}\n",
        "    print(f\"[IMB] train raw counts={class_counts}  class_weights={class_weights}\")\n",
        "\n",
        "    # *** class weights for training\n",
        "    # Build & train\n",
        "    input_shape = X_tr.shape[1:]\n",
        "    model = build_model(input_shape)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    cb_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    cb_rlr   = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n",
        "                                                    min_lr=1e-6, verbose=1)\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        validation_data=(X_va, y_va),\n",
        "        epochs=100,\n",
        "        batch_size=64,\n",
        "        class_weight=class_weights,   # keep class_weight\n",
        "        callbacks=[cb_early, cb_rlr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "\n",
        "    # Threshold scan on validation\n",
        "    p_val = model.predict(X_va, verbose=0)\n",
        "    best_th, th_meta = pick_threshold_on_val(\n",
        "        p_val, y_va,\n",
        "        # FIX: Use defined global constants\n",
        "        step=THRESH_SCAN_STEP,\n",
        "        fph_cap=FPH_CAP,\n",
        "        stride_sec=STRIDE_SEC,\n",
        "        min_sens=0.60,\n",
        "        objective=\"sens\",\n",
        "        refractory_min=10,   #  ** align with KPI\n",
        "        min_run_len=MIN_RUN_LEN # Use defined global constant\n",
        "    )\n",
        "    print(f\"[THRESH] best_th={best_th:.2f} meta={th_meta}\")\n",
        "\n",
        "\n",
        "    # Test: apply threshold -> 3-class -> K-window smoothing *** Too smoothing that pre-ictal is draged to 0\n",
        "    p_te = model.predict(X_te, verbose=0)\n",
        "    p_pos_te = p_te[:,1] + p_te[:,2]\n",
        "    y_hat_bin = (p_pos_te >= best_th).astype(int)\n",
        "    y_hat = np.zeros_like(y_te)\n",
        "    pos_idx = np.where(y_hat_bin == 1)[0]\n",
        "    if len(pos_idx):\n",
        "        y_hat[pos_idx] = np.where(p_te[pos_idx,2] >= p_te[pos_idx,1], 2, 1)\n",
        "    y_hat_sm = min_consecutive_positive(y_hat, min_len=MIN_RUN_LEN) # ** minimum continuous positive = MIN_RUN_LEN\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"\\n--- Classification Report (Per Window, post K-smooth) ---\")\n",
        "    print(classification_report(y_te, y_hat_sm, target_names=[\"Inter-ictal\",\"Pre-ictal\",\"Ictal\"], zero_division=0))\n",
        "\n",
        "    sens = (np.sum((y_te>0) & (y_hat_sm>0)) / max(np.sum(y_te>0), 1)) # ** align validation and test of FPH\n",
        "    fph  = fp_per_hour_events(y_te, y_hat_sm, stride_sec=STRIDE_SEC,\n",
        "                              refractory_min=10, min_run_len=MIN_RUN_LEN)\n",
        "\n",
        "    wt_avg, wt_med, n_epi, n_det = compute_warning_time_minutes(y_te, (y_hat_sm>0).astype(int), stride_sec=STRIDE_SEC)\n",
        "    print(f\"[KPI] Sens={sens*100:.2f}%  FP/h={fph:.4f}  Warning(min) avg/med={wt_avg:.2f}/{wt_med:.2f}  \"\n",
        "          f\"Episodes={n_epi} Detected={n_det}\")\n",
        "\n",
        "    # Export per-fold artifacts\n",
        "    # --- export: build export-safe twin (non-cuDNN) and copy weights ---\n",
        "    export_model = build_model(input_shape, export_safe=True)\n",
        "    export_model.set_weights(model.get_weights())\n",
        "\n",
        "    keras_path  = os.path.join(OUTPUT_DIR, f\"heavy_model_{test_pid}.keras\")\n",
        "    tflite_path = os.path.join(OUTPUT_DIR, f\"heavy_model_{test_pid}_fp16.tflite\")\n",
        "\n",
        "    # Save Keras (export-safe)\n",
        "    export_model.save(keras_path)\n",
        "\n",
        "    # Convert to FP16 TFLite\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(export_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "    tflite_fp16 = converter.convert()\n",
        "    with open(tflite_path, \"wb\") as f:\n",
        "        f.write(tflite_fp16)\n",
        "\n",
        "\n",
        "    meta = {\n",
        "        \"fold\": {\"train\": train_pids, \"val\": [val_pid], \"test\": [test_pid]},\n",
        "        \"window_sec\": WINDOW_DURATION_SEC,\n",
        "        \"stride_sec\": STRIDE_SEC,\n",
        "        \"threshold\": float(best_th),\n",
        "        \"threshold_meta\": th_meta,\n",
        "        # FIX: Use MIN_RUN_LEN instead of the undefined K_CONSENSUS\n",
        "        \"min_run_len\": int(MIN_RUN_LEN),\n",
        "        \"metrics_test\": {\n",
        "            \"sensitivity\": float(sens),\n",
        "            \"fp_per_hour\": float(fph),\n",
        "            \"warning_time_avg_min\": float(wt_avg),\n",
        "            \"warning_time_med_min\": float(wt_med),\n",
        "            \"episodes\": int(n_epi),\n",
        "            \"episodes_detected\": int(n_det),\n",
        "        }\n",
        "    }\n",
        "    meta_path = os.path.join(OUTPUT_DIR, f\"inference_meta_{test_pid}.json\")\n",
        "    with open(meta_path, \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    print(f\"[EXPORT] {keras_path}\")\n",
        "    print(f\"[EXPORT] {tflite_path}\")\n",
        "    print(f\"[EXPORT] {meta_path}\")\n",
        "\n",
        "    return {\"test\": test_pid, \"val\": val_pid, \"train\": train_pids,\n",
        "            \"sens\": sens, \"fph\": fph, \"wt_avg\": wt_avg, \"wt_med\": wt_med}\n",
        "\n",
        "def main():\n",
        "    # Optional: let TF grow GPU memory as needed\n",
        "    try:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Ring LOPOCV: test=i, val=i+1, others=train\n",
        "    results = []\n",
        "    n = len(PATIENTS)\n",
        "    for i, test_pid in enumerate(PATIENTS):\n",
        "        val_pid = PATIENTS[(i+1) % n]\n",
        "        train_pids = [p for p in PATIENTS if p not in (test_pid, val_pid)]\n",
        "        res = run_fold(test_pid, val_pid, train_pids)\n",
        "        results.append(res)\n",
        "\n",
        "    # Summary across folds\n",
        "    if results:\n",
        "        sens = np.array([r[\"sens\"] for r in results])\n",
        "        fph  = np.array([r[\"fph\"]  for r in results])\n",
        "        wt_a = np.array([r[\"wt_avg\"] for r in results])\n",
        "        wt_m = np.array([r[\"wt_med\"] for r in results])\n",
        "        print(\"\\n===== LOPOCV SUMMARY =====\")\n",
        "        print(f\"Sensitivity mean/median: {sens.mean()*100:.2f}% / {np.median(sens)*100:.2f}%\")\n",
        "        print(f\"FP/h       mean/median: {fph.mean():.4f} / {np.median(fph):.4f}\")\n",
        "        print(f\"WarnTime(min) avg/med : {wt_a.mean():.2f} / {np.median(wt_m):.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YHLaMoz3iazV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a82804-6dfa-4a3e-f35c-18614fda8a0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting heavy_model_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python heavy_model_2.py"
      ],
      "metadata": {
        "id": "5YZAypqx6WG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a7f4fc-1840-47e6-8ab2-7b9bf9bc1455"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-12 15:27:23.538224: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760282843.814828    2834 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760282843.900952    2834 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760282844.526955    2834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282844.526996    2834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282844.527002    2834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282844.527006    2834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "===== FOLD | test=chb05 val=chb06 train=['chb07', 'chb08'] =====\n",
            "[IMB] train raw counts=Counter({np.int64(0): 124200, np.int64(1): 18000, np.int64(2): 1853})  class_weights={np.int64(0): 0.38661567364465915, np.int64(1): 2.667648148148148, np.int64(2): 25.91347364633927}\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "I0000 00:00:1760282861.281033    2834 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\u001b[1mModel: \"sequential\"\u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
            "│ conv1d (\u001b[94mConv1D\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m508\u001b[0m, \u001b[32m64\u001b[0m)        │         \u001b[32m1,344\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ batch_normalization             │ (\u001b[96mNone\u001b[0m, \u001b[32m508\u001b[0m, \u001b[32m64\u001b[0m)        │           \u001b[32m256\u001b[0m │\n",
            "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ max_pooling1d (\u001b[94mMaxPooling1D\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m254\u001b[0m, \u001b[32m64\u001b[0m)        │             \u001b[32m0\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dropout (\u001b[94mDropout\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m254\u001b[0m, \u001b[32m64\u001b[0m)        │             \u001b[32m0\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ bidirectional (\u001b[94mBidirectional\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m254\u001b[0m, \u001b[32m256\u001b[0m)       │       \u001b[32m197,632\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dropout_1 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m254\u001b[0m, \u001b[32m256\u001b[0m)       │             \u001b[32m0\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ bidirectional_1 (\u001b[94mBidirectional\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)            │       \u001b[32m164,352\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dropout_2 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dense (\u001b[94mDense\u001b[0m)                   │ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)            │        \u001b[32m16,512\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dropout_3 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)            │             \u001b[32m0\u001b[0m │\n",
            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
            "│ dense_1 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m)              │           \u001b[32m387\u001b[0m │\n",
            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m380,483\u001b[0m (1.45 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m380,355\u001b[0m (1.45 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m128\u001b[0m (512.00 B)\n",
            "2025-10-12 15:27:43.773506: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1180082176 exceeds 10% of free system memory.\n",
            "2025-10-12 15:27:44.871141: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1180082176 exceeds 10% of free system memory.\n",
            "Epoch 1/100\n",
            "I0000 00:00:1760282870.896052    2940 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4511 - loss: 0.93732025-10-12 15:30:31.054000: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1869021184 exceeds 10% of free system memory.\n",
            "2025-10-12 15:30:32.943880: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1869021184 exceeds 10% of free system memory.\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 102ms/step - accuracy: 0.4510 - loss: 0.9372 - val_accuracy: 0.0805 - val_loss: 1.0857 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.3966 - loss: 0.7689 - val_accuracy: 0.2324 - val_loss: 1.1611 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.4546 - loss: 0.7369 - val_accuracy: 0.4427 - val_loss: 0.9302 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5231 - loss: 0.7246 - val_accuracy: 0.4763 - val_loss: 1.0617 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5177 - loss: 0.7415 - val_accuracy: 0.2906 - val_loss: 1.4061 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m2250/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5399 - loss: 0.7520\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5399 - loss: 0.7521 - val_accuracy: 0.2926 - val_loss: 1.4450 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5627 - loss: 0.7854 - val_accuracy: 0.2747 - val_loss: 1.3431 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5759 - loss: 0.8490 - val_accuracy: 0.4130 - val_loss: 1.2364 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m2250/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5719 - loss: 0.8755\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5719 - loss: 0.8756 - val_accuracy: 0.4451 - val_loss: 1.0643 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5848 - loss: 0.8051 - val_accuracy: 0.3335 - val_loss: 1.6487 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5802 - loss: 0.8658 - val_accuracy: 0.3996 - val_loss: 1.1039 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5815 - loss: 0.9087\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 81ms/step - accuracy: 0.5815 - loss: 0.9087 - val_accuracy: 0.4082 - val_loss: 1.3218 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m2251/2251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 81ms/step - accuracy: 0.5831 - loss: 0.9176 - val_accuracy: 0.4326 - val_loss: 1.0651 - learning_rate: 1.2500e-04\n",
            "2025-10-12 16:08:13.751982: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1869021184 exceeds 10% of free system memory.\n",
            "[THRESH] best_th=0.95 meta={'rule': 'sens_or_f1_under_event_fph_cap', 'th': 0.9500000000000001, 'sens': 0.001392665296107169, 'fph': 0.03379123586751959, 'f1_pos': 0.0027537372147915028, 'params': {'refractory_min': 10, 'min_run_len': 2}}\n",
            "\n",
            "--- Classification Report (Per Window, post K-smooth) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Inter-ictal       0.95      1.00      0.97    258575\n",
            "   Pre-ictal       0.00      0.00      0.00     13800\n",
            "       Ictal       0.00      0.00      0.00      1131\n",
            "\n",
            "    accuracy                           0.95    273506\n",
            "   macro avg       0.32      0.33      0.32    273506\n",
            "weighted avg       0.89      0.95      0.92    273506\n",
            "\n",
            "[KPI] Sens=0.00%  FP/h=0.1949  Warning(min) avg/med=74.63/68.09  Episodes=5 Detected=5\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Saved artifact at '/tmp/tmpwofv_vc9'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 4), dtype=tf.float32, name='keras_tensor_12')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133019337952912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337953104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337952528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337965200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337951952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337951760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019409710736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337952336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337951376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337950992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337953296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626478288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626474640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626477904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337949648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626477712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626478864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626479056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133019337951568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626477328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626475792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626478096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626477136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626478672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626476368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133018626475600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1760285553.752622    2834 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1760285553.757142    2834 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1760285553.800482    2834 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1_1/bidirectional_2_1/backward_lstm_2_1/TensorArrayV2_1@__inference_function_660146\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_660261\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n",
            "loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1_1/bidirectional_2_1/backward_lstm_2_1/TensorArrayV2_1@__inference_function_660146\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_660261\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n",
            "error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/heavy_model_2.py\", line 366, in <module>\n",
            "    main()\n",
            "  File \"/content/heavy_model_2.py\", line 351, in main\n",
            "    res = run_fold(test_pid, val_pid, train_pids)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/heavy_model_2.py\", line 303, in run_fold\n",
            "    tflite_fp16 = converter.convert()\n",
            "                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\", line 1250, in wrapper\n",
            "    return self._convert_and_export_metrics(convert_func, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\", line 1202, in _convert_and_export_metrics\n",
            "    result = convert_func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\", line 1768, in convert\n",
            "    saved_model_convert_result = self._convert_as_saved_model()\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\", line 1749, in _convert_as_saved_model\n",
            "    return super(TFLiteKerasModelConverterV2, self).convert(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\", line 1487, in convert\n",
            "    result = _convert_graphdef(\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\", line 212, in wrapper\n",
            "    raise converter_error from None  # Re-throws the exception.\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\", line 205, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py\", line 885, in convert_graphdef\n",
            "    data = convert(\n",
            "           ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py\", line 350, in convert\n",
            "    raise converter_error\n",
            "tensorflow.lite.python.convert_phase.ConverterError: <unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1_1/bidirectional_2_1/backward_lstm_2_1/TensorArrayV2_1@__inference_function_660146\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_660261\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n",
            "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
            "<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1_1/bidirectional_2_1/backward_lstm_2_1/TensorArrayV2_1@__inference_function_660146\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_660261\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n",
            "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
            "<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1); plt.plot(history.history[\"accuracy\"]); plt.plot(history.history[\"val_accuracy\"]); plt.title(\"Accuracy\"); plt.legend([\"train\",\"val\"])\n",
        "    plt.subplot(1,2,2); plt.plot(history.history[\"loss\"]); plt.plot(history.history[\"val_loss\"]); plt.title(\"Loss\"); plt.legend([\"train\",\"val\"])\n",
        "    plt.tight_layout(); plt.savefig(\"training_curves.png\"); plt.show()\n"
      ],
      "metadata": {
        "id": "7QmCGKzgyLq_"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}